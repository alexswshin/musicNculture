{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lyric Sentiment Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from stop_words import get_stop_words\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "stop = get_stop_words('en')\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "fname = DATA_PATH + 'billboard_1970_current.csv'\n",
    "df = pd.read_csv(fname,sep='@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    normalized_split = normalized.split()\n",
    "    # deviding the lyric into verse 1 and verse 2\n",
    "    return [normalized_split[:int(len(normalized_split)/2)],normalized_split[int(len(normalized_split)/2):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusExtraction(lyric):\n",
    "    tmp = clean(lyric)\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "    dictionary = corpora.Dictionary(tmp)\n",
    "\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in tmp]\n",
    "\n",
    "    # Creating the object for LDA model using gensim library\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "    # Running and Trainign LDA model on the document term matrix.\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "    print(ldamodel.print_topics(num_topics=4, num_words=3))\n",
    "    \n",
    "# https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicModelling(artist, title):\n",
    "    lyric = df.loc[(df.artist == artist) & (df.title == title),['lyric']].values[0][0]\n",
    "    corpusExtraction(lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.072*\"na\" + 0.062*\"change\" + 0.054*\"make\"'), (1, '0.009*\"widow\" + 0.009*\"that\" + 0.009*\"blind\"'), (2, '0.009*\"one\" + 0.009*\"street\" + 0.009*\"widow\"')]\n"
     ]
    }
   ],
   "source": [
    "topicModelling('Michael Jackson', 'Man In The Mirror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)', 'heart' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "def sentimentAnalysisHelper(lyric):\n",
    "    # train positive and negative features\n",
    "    positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "    negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "    neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    "    \n",
    "    train_set = negative_features + positive_features + neutral_features\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # setting up lyric materials\n",
    "    lyric = lyric.lower()\n",
    "    words = lyric.split(' ')\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    neg = 0\n",
    "    pos = 0\n",
    "    for word in words:\n",
    "        classResult = classifier.classify( word_feats(word))\n",
    "        if classResult == 'neg':\n",
    "            neg = neg + 1\n",
    "        if classResult == 'pos':\n",
    "            pos = pos + 1\n",
    "\n",
    "    print('Positive: ' + str(round(float(pos)/len(words)*100,2)) + \"%\")\n",
    "    print('Negative: ' + str(round(float(neg)/len(words)*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(artist, title):\n",
    "    lyric = df.loc[(df.artist == artist) & (df.title == title),['lyric']].values[0][0]\n",
    "    sentimentAnalysisHelper(lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 69.18%\n",
      "Negative: 7.06%\n"
     ]
    }
   ],
   "source": [
    "sentimentAnalysis('Michael Jackson', 'Man In The Mirror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.072*\"na\" + 0.062*\"change\" + 0.054*\"make\"'), (1, '0.009*\"somebody\" + 0.009*\"disregard\" + 0.009*\"deeply\"'), (2, '0.009*\"home\" + 0.009*\"soul\" + 0.009*\"somebody\"')]\n"
     ]
    }
   ],
   "source": [
    "topicModelling('Michael Jackson', 'Man In The Mirror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
